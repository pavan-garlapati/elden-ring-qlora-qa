# ğŸ—¡ï¸ Elden Ring QA â€” Domain-Specific Question Answering with QLoRA

A fine-tuned Phi-2 (2.7B) model for answering questions about Elden Ring, including weapon stats, boss strategies, spell requirements, NPC locations, and lore.

## ğŸ”— Quick Links

- **Model (HuggingFace):** [your-username/elden-ring-phi2-qlora](https://huggingface.co/your-username/elden-ring-phi2-qlora)
- **Dataset (HuggingFace):** [your-username/elden-ring-qa-dataset](https://huggingface.co/datasets/your-username/elden-ring-qa-dataset)
- **Training Notebook:** [EldenRing_FineTuning.ipynb](./EldenRing_FineTuning.ipynb)

## ğŸ“Š Results

Evaluation metrics comparing fine-tuned model vs baseline Phi-2 are generated by the training notebook. Key finding: significant improvement in ROUGE-2 (domain vocabulary acquisition) with successful domain terminology learning. See `eval_results.json` and `evaluation_comparison.png` for exact values.

## ğŸ—ï¸ Project Structure

```
EldenRing/
â”œâ”€â”€ data/                          # Raw CSV files from Kaggle
â”‚   â”œâ”€â”€ weapons.csv                # 402 weapons
â”‚   â”œâ”€â”€ bosses.csv                 # 153 bosses
â”‚   â”œâ”€â”€ elden_ring_boss_stats_clean.csv  # 142 boss combat stats
â”‚   â”œâ”€â”€ elden_ring_weapon.csv      # 307 weapon scaling data
â”‚   â”œâ”€â”€ armors.csv                 # 723 armor pieces
â”‚   â”œâ”€â”€ incantations.csv           # 129 incantations
â”‚   â”œâ”€â”€ sorceries.csv              # 84 sorceries
â”‚   â”œâ”€â”€ npcs.csv                   # 109 NPCs
â”‚   â”œâ”€â”€ locations.csv              # 286 locations
â”‚   â”œâ”€â”€ creatures.csv              # 205 creatures
â”‚   â”œâ”€â”€ skills.csv                 # 257 skills
â”‚   â””â”€â”€ ashesOfWar.csv             # 117 ashes of war
â”œâ”€â”€ extract_lore.py                # Stage 1: HTML lore extraction
â”œâ”€â”€ fuse_data.py                   # Stage 2: Data fusion & enrichment
â”œâ”€â”€ generate_qa.py                 # Stage 3: QA pair generation
â”œâ”€â”€ master_lore.json               # Extracted lore library
â”œâ”€â”€ elden_ring_enriched.json       # Enriched intermediate data
â”œâ”€â”€ elden_ring_final_train.jsonl   # Final QA dataset (4,000+ pairs)
â”œâ”€â”€ EldenRing_FineTuning.ipynb     # Training & evaluation notebook
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # This file
```

## ğŸš€ Quick Start

### Load the Fine-Tuned Model

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
from peft import PeftModel
import torch

# Quantization config
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_use_double_quant=True,
)

# Load base + adapter
base = AutoModelForCausalLM.from_pretrained(
    "microsoft/phi-2",
    quantization_config=bnb_config,
    device_map="auto",
    trust_remote_code=True,
)
model = PeftModel.from_pretrained(base, "your-username/elden-ring-phi2-qlora")
tokenizer = AutoTokenizer.from_pretrained("your-username/elden-ring-phi2-qlora")

# Ask a question
prompt = """### Instruction:
What weapons are good against Mohg, Lord of Blood?

### Response:
"""
inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
outputs = model.generate(**inputs, max_new_tokens=128, repetition_penalty=1.5, no_repeat_ngram_size=3)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```

### Regenerate the Dataset

```bash
# Install dependencies
pip install -r requirements.txt

# Run the data pipeline
python extract_lore.py          # â†’ master_lore.json
python fuse_data.py             # â†’ elden_ring_enriched.json  
python generate_qa.py           # â†’ elden_ring_final_train.jsonl
```

### Train the Model

Open `EldenRing_FineTuning.ipynb` in Google Colab with an A100, L4, or T4 GPU and run all cells.

## ğŸ“¦ Dependencies

```
torch>=2.1
transformers>=4.44
peft>=0.12
bitsandbytes>=0.43
datasets
accelerate
evaluate
rouge_score
bert_score
trl
scipy
sentencepiece
protobuf
triton
beautifulsoup4
pandas
matplotlib
```

## ğŸ¯ Key Features

- **Cross-entity analysis**: Boss vulnerability â†’ weapon recommendation pipeline
- **10 entity types**: Weapons, bosses, armors, NPCs, locations, sorceries, incantations, creatures, skills, ashes of war
- **20+ question types**: Lore, stats, requirements, weaknesses, strategies, locations, drops, status effects
- **Per-build recommendations**: Strength, Dexterity, Intelligence, Faith, Arcane weapon suggestions per boss
- **4,000+ QA pairs**: Generated from 3 fused data sources

## ğŸ“ Data Sources

1. [Kaggle â€” Ultimate Elden Ring with Shadow of the Erdtree DLC](https://www.kaggle.com/datasets/pedroaltobelli/ultimate-elden-ring-with-shadow-of-the-erdtree-dlc)
2. [GitHub â€” Impalers-Archive](https://github.com/ividyon/Impalers-Archive) (DLC text dump)
3. [GitHub â€” Carian-Archive](https://github.com/AsteriskAmpersand/Carian-Archive) (Base game text dump)

## ğŸ“„ License

This project is for educational purposes. Game data belongs to FromSoftware/Bandai Namco.
